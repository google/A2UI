{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Learning Demo - Quickstart\n",
    "\n",
    "A full-stack A2UI sample demonstrating personalized educational content generation.\n",
    "\n",
    "**Contributed by Google Public Sector's Rapid Innovation Team.**\n",
    "\n",
    "![Personalized Learning Demo](assets/hero.png)\n",
    "\n",
    "---\n",
    "\n",
    "## The Scenario\n",
    "\n",
    "**Maria Thompson** is a pre-med student at Cymbal University preparing for the MCAT. She excels in biology (92%) but struggles with chemistry concepts—particularly the common misconception that \"energy is stored in ATP bonds.\"\n",
    "\n",
    "How we find that information about a student's misconceptions across multiple courses is actually part of a broader project at Google Public Sector. But for now, we're just running with information we have related to one of those misconceptions, represented by the text files in the `learner_context/` directory.\n",
    "\n",
    "This demo includes a [learner profile visualization](http://localhost:5174/maria-context.html) showing Maria's:\n",
    "- Academic background and current proficiency levels\n",
    "- Identified misconceptions to address\n",
    "- Learning preferences (visual-kinesthetic, sports/gym analogies)\n",
    "\n",
    "This profile represents the kind of data a real personalization pipeline would generate from learning management systems, assessment results, and curriculum graphs. Once we have that data, how do we best use it to impact a student's learning trajectory?\n",
    "\n",
    "We think the A2UI framework enables an excellent learning experience, and this demo intends to show how.\n",
    "\n",
    "---\n",
    "\n",
    "## How Content Is Generated\n",
    "\n",
    "**Content Source:** [OpenStax](https://openstax.org/) — free, peer-reviewed textbooks covering 167 chapters across biology, chemistry, physics, and more.\n",
    "\n",
    "**Generation Pipeline:**\n",
    "- User requests a topic (e.g., \"Help me understand ATP\")\n",
    "- The agent uses an LLM to match the topic to the most relevant OpenStax chapter\n",
    "- Content is fetched and transformed into A2UI components (flashcards, quizzes)\n",
    "- The frontend renders whatever A2UI JSON the agent returns\n",
    "\n",
    "**Learn More:**\n",
    "- [How A2UI Works](http://localhost:5174/a2ui-primer.html) — interactive explanation in the demo\n",
    "- [A2UI Specification](../../docs/) — canonical documentation in this repo\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "| Concept | What This Demo Shows |\n",
    "|---------|---------------------|\n",
    "| **Remote Agent Deployment** | Deploy an AI agent to Vertex AI Agent Engine that runs independently from your UI |\n",
    "| **A2A Protocol** | Use the Agent-to-Agent protocol to communicate between your frontend and the remote agent |\n",
    "| **Custom UI Components** | Extend A2UI with custom components (Flashcard, QuizCard) beyond the standard library |\n",
    "| **Dynamic Content Generation** | Generate personalized A2UI JSON on-the-fly based on user requests |\n",
    "| **Intelligent Content Matching** | Use LLMs to match user topics to relevant textbook content (167 OpenStax chapters) |\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture\n",
    "\n",
    "![Architecture Diagram](assets/architecture.jpg)\n",
    "\n",
    "In production agentic systems:\n",
    "- **Agents run remotely** — they scale independently, can be updated without redeploying the UI, and may be operated by third parties\n",
    "- **UI is decoupled** — the frontend renders whatever A2UI JSON the agent sends, without knowing the agent's implementation\n",
    "- **A2A enables interoperability** — any A2A-compatible agent can power your UI, regardless of how it's built\n",
    "\n",
    "---\n",
    "\n",
    "## How This Notebook Is Organized\n",
    "\n",
    "| Section | What It Does |\n",
    "|---------|--------------|\n",
    "| **Step 1: Environment Setup** | Creates Python virtual environment and installs all dependencies |\n",
    "| **Step 2: Configuration** | Sets your GCP project ID |\n",
    "| **Step 3: GCP Authentication** | Authenticates with Google Cloud and enables required APIs |\n",
    "| **Step 4: Deploy Agent** | Deploys the AI agent to Vertex AI Agent Engine |\n",
    "| **Step 5: Configure & Run** | Creates config files and launches the demo |\n",
    "| **Step 6 (Optional)** | Generate audio/video content with NotebookLM |\n",
    "| **Appendix: Local Development** | Run entirely locally without cloud deployment |\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Node.js 18+** — [Download](https://nodejs.org/)\n",
    "- **Python 3.11+** — [Download](https://www.python.org/downloads/)\n",
    "- **Google Cloud project with billing enabled** — [Console](https://console.cloud.google.com/)\n",
    "- **gcloud CLI installed** — [Install Guide](https://cloud.google.com/sdk/docs/install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Run this cell first to load all Python modules used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "First, we'll create an isolated Python environment and install all dependencies. This ensures the demo doesn't conflict with other Python projects on your system.\n",
    "\n",
    "### 1a. Create Python Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create virtual environment if it doesn't exist\n",
    "venv_path = os.path.join(os.getcwd(), \".venv\")\n",
    "if not os.path.exists(venv_path):\n",
    "    print(\"Creating Python virtual environment...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"venv\", \".venv\"], check=True)\n",
    "    print(f\"✅ Created virtual environment at {venv_path}\")\n",
    "else:\n",
    "    print(f\"✅ Virtual environment already exists at {venv_path}\")\n",
    "\n",
    "print(\"\\n⚠️  IMPORTANT: Restart your Jupyter kernel to use the new environment!\")\n",
    "print(\"   In VS Code: Click the kernel selector (top right) → Select '.venv'\")\n",
    "print(\"   In JupyterLab: Kernel → Change Kernel → Python (.venv)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Install Python Dependencies\n",
    "\n",
    "After selecting the `.venv` kernel, run this cell to install all required Python packages.\n",
    "\n",
    "**Note:** We explicitly use `https://pypi.org/simple/` to ensure packages come from the official Python Package Index, avoiding issues with corporate proxies or custom registries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python dependencies using the canonical PyPI index\n",
    "print(\"Installing Python dependencies from PyPI...\")\n",
    "packages = [\n",
    "    \"google-adk>=0.3.0\",\n",
    "    \"google-genai>=1.0.0\",\n",
    "    \"google-cloud-storage>=2.10.0\",\n",
    "    \"python-dotenv>=1.0.0\",\n",
    "    \"litellm>=1.0.0\",\n",
    "    \"vertexai\",\n",
    "]\n",
    "\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "    \"--index-url\", \"https://pypi.org/simple/\",\n",
    "    \"--trusted-host\", \"pypi.org\",\n",
    "    \"--trusted-host\", \"files.pythonhosted.org\",\n",
    "    *packages\n",
    "], check=True)\n",
    "\n",
    "print(\"✅ Python dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Install Node.js Dependencies\n",
    "\n",
    "Now we'll install the frontend dependencies. This includes the A2UI renderer library and the demo's own packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the A2UI Lit renderer (using public npm registry)\n",
    "print(\"Building A2UI Lit renderer...\")\n",
    "subprocess.run(\n",
    "    \"npm install --registry https://registry.npmjs.org/ && npm run build\",\n",
    "    shell=True,\n",
    "    cwd=\"../../renderers/lit\",\n",
    "    check=True\n",
    ")\n",
    "print(\"✅ A2UI renderer built\")\n",
    "\n",
    "# Install demo dependencies\n",
    "print(\"\\nInstalling demo dependencies...\")\n",
    "subprocess.run(\n",
    "    \"npm install --registry https://registry.npmjs.org/\",\n",
    "    shell=True,\n",
    "    check=True\n",
    ")\n",
    "print(\"✅ Demo dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configuration\n",
    "\n",
    "Set your Google Cloud project ID below. This is the project where the agent will be deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"your-project-id\"  # <-- CHANGE THIS to your GCP project ID\n",
    "LOCATION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: GCP Authentication & API Setup\n",
    "\n",
    "Authenticate with Google Cloud and enable the required APIs. This will open browser windows for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Google Cloud\n",
    "!gcloud auth login\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable required APIs\n",
    "!gcloud services enable aiplatform.googleapis.com\n",
    "!gcloud services enable cloudbuild.googleapis.com\n",
    "!gcloud services enable storage.googleapis.com\n",
    "!gcloud services enable cloudresourcemanager.googleapis.com\n",
    "\n",
    "# Create staging bucket for Agent Engine (if it doesn't exist)\n",
    "!gsutil mb -l {LOCATION} gs://{PROJECT_ID}_cloudbuild 2>/dev/null || echo \"Bucket already exists\"\n",
    "\n",
    "print(\"\\n✅ GCP APIs enabled and staging bucket ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Deploy the A2UI Agent\n",
    "\n",
    "The agent generates personalized learning content and runs on Vertex AI Agent Engine. Deployment takes 2-5 minutes.\n",
    "\n",
    "**Why deploy remotely?** A2UI is designed for remote agents - your UI runs in the browser while the agent runs on a server. This mirrors real-world architectures where agents scale independently and may even be operated by third parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the agent to Vertex AI Agent Engine (takes 2-5 minutes)\n",
    "print(\"Deploying agent to Vertex AI Agent Engine...\")\n",
    "print(\"This takes 2-5 minutes. Watch for the Resource ID at the end.\\n\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"deploy.py\", \"--project\", PROJECT_ID, \"--location\", LOCATION],\n",
    "    cwd=\"agent\"\n",
    ")\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"\\n❌ Deployment failed. Check the error messages above.\")\n",
    "else:\n",
    "    print(\"\\n✅ Deployment complete! Copy the Resource ID from the output above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Configure & Run\n",
    "\n",
    "Fill in the Resource ID from the deployment output above, then create the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your project NUMBER (different from project ID)\n",
    "result = subprocess.run(\n",
    "    [\"gcloud\", \"projects\", \"describe\", PROJECT_ID, \"--format=value(projectNumber)\"], \n",
    "    capture_output=True, text=True\n",
    ")\n",
    "PROJECT_NUMBER = result.stdout.strip()\n",
    "print(f\"Project Number: {PROJECT_NUMBER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the Resource ID from the deployment output in Step 4\n",
    "AGENT_RESOURCE_ID = \"YOUR_RESOURCE_ID_HERE\"  # <-- PASTE YOUR RESOURCE ID HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file\n",
    "env_content = f\"\"\"# Generated by Quickstart.ipynb\n",
    "GOOGLE_CLOUD_PROJECT={PROJECT_ID}\n",
    "AGENT_ENGINE_PROJECT_NUMBER={PROJECT_NUMBER}\n",
    "AGENT_ENGINE_RESOURCE_ID={AGENT_RESOURCE_ID}\n",
    "\"\"\"\n",
    "\n",
    "with open(\".env\", \"w\") as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "print(\"Created .env file:\")\n",
    "print(env_content)\n",
    "print(\"✅ Configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Demo\n",
    "\n",
    "Everything is set up! Run these commands in your terminal (not in the notebook):\n",
    "\n",
    "```bash\n",
    "cd samples/personalized_learning\n",
    "npm run dev\n",
    "```\n",
    "\n",
    "Then open **http://localhost:5174**\n",
    "\n",
    "### Try These Prompts\n",
    "\n",
    "| Prompt | What Happens |\n",
    "|--------|-------------|\n",
    "| \"Help me understand ATP\" | Generates flashcards from OpenStax |\n",
    "| \"Quiz me on bond energy\" | Interactive quiz cards |\n",
    "| \"Play the podcast\" | Audio player (requires Step 6) |\n",
    "| \"Show me a video\" | Video player (requires Step 6) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6 (Optional): Generate Audio & Video with NotebookLM\n",
    "\n",
    "The demo includes audio and video players, but you need to generate the media files. NotebookLM can create personalized podcasts based on the learner context.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- A Google account with access to [NotebookLM](https://notebooklm.google.com/)\n",
    "- The `learner_context/` files from this demo\n",
    "\n",
    "---\n",
    "\n",
    "### Part A: Generate a Personalized Podcast\n",
    "\n",
    "**1. Create a NotebookLM Notebook**\n",
    "\n",
    "Go to [notebooklm.google.com](https://notebooklm.google.com/) and create a new notebook.\n",
    "\n",
    "**2. Upload Learner Context Files**\n",
    "\n",
    "Upload all files from the `learner_context/` directory:\n",
    "- `01_maria_learner_profile.txt` - Maria's background and learning preferences  \n",
    "- `02_chemistry_bond_energy.txt` - Bond energy concepts\n",
    "- `03_chemistry_thermodynamics.txt` - Thermodynamics content\n",
    "- `04_biology_atp_cellular_respiration.txt` - ATP and cellular respiration\n",
    "- `05_misconception_resolution.txt` - Common misconceptions to address\n",
    "- `06_mcat_practice_concepts.txt` - MCAT-focused content\n",
    "\n",
    "These files give NotebookLM the context to generate personalized content.\n",
    "\n",
    "**3. Generate the Audio Overview**\n",
    "\n",
    "- Click **Notebook guide** in the right sidebar\n",
    "- Click **Audio Overview** → **Generate**\n",
    "- Wait for generation to complete (typically 2-5 minutes)\n",
    "- NotebookLM will create a podcast-style discussion about the uploaded content\n",
    "\n",
    "**4. Customize the Audio (Optional)**\n",
    "\n",
    "Before generating, you can click **Customize** to provide specific instructions:\n",
    "\n",
    "```\n",
    "Create a podcast for Maria, a pre-med student preparing for the MCAT. \n",
    "Use gym and fitness analogies since she loves working out.\n",
    "Focus on explaining why \"energy stored in bonds\" is a misconception.\n",
    "Make it conversational and engaging, about 5-7 minutes long.\n",
    "```\n",
    "\n",
    "**5. Download and Install the Podcast**\n",
    "\n",
    "- Once generated, click the **⋮** menu on the audio player\n",
    "- Select **Download**\n",
    "- Save the file as `podcast.m4a`\n",
    "- Copy to the demo's assets directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your downloaded podcast to the assets directory\n",
    "# Replace ~/Downloads/podcast.m4a with your actual download path\n",
    "!cp ~/Downloads/podcast.m4a public/assets/podcast.m4a\n",
    "\n",
    "# Verify the file was copied\n",
    "!ls -la public/assets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Part B: Create a Video\n",
    "\n",
    "In NotebookLM with your learner context loaded:\n",
    "- In the **studio** tab, click \"Video Overview\"\n",
    "- This creates a video file you can view and export\n",
    "\n",
    "Export your video as MP4 and copy to the assets directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your video to the assets directory\n",
    "# Replace ~/Downloads/demo.mp4 with your actual file path\n",
    "!cp ~/Downloads/demo.mp4 public/assets/demo.mp4\n",
    "\n",
    "# Verify both media files are in place\n",
    "!ls -la public/assets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Use Placeholder/Stock Content\n",
    "\n",
    "For demo purposes, you can use any MP4 video file. Rename it to `demo.mp4` and place it in `public/assets/`.\n",
    "\n",
    "---\n",
    "\n",
    "### Verify Media Files\n",
    "\n",
    "After copying your files, verify they're accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Media files status:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "podcast_path = \"public/assets/podcast.m4a\"\n",
    "video_path = \"public/assets/demo.mp4\"\n",
    "\n",
    "if os.path.exists(podcast_path):\n",
    "    size_mb = os.path.getsize(podcast_path) / (1024 * 1024)\n",
    "    print(f\"✅ Podcast: {podcast_path} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"❌ Podcast: {podcast_path} NOT FOUND\")\n",
    "    \n",
    "if os.path.exists(video_path):\n",
    "    size_mb = os.path.getsize(video_path) / (1024 * 1024)\n",
    "    print(f\"✅ Video: {video_path} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"❌ Video: {video_path} NOT FOUND\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"\\nRun 'npm run dev' and try:\")\n",
    "print('  • \"Play the podcast\" - to hear the audio')\n",
    "print('  • \"Show me a video\" - to watch the video')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Content Attribution\n",
    "\n",
    "### OpenStax\n",
    "\n",
    "Educational content is sourced from [OpenStax](https://openstax.org/), licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Specifically: [Biology for AP® Courses](https://openstax.org/details/books/biology-ap-courses) - OpenStax, Rice University\n",
    "\n",
    "---\n",
    "\n",
    "## Security Notice\n",
    "\n",
    "> **Warning:** When building production applications, treat any agent outside your control as potentially untrusted. This demo connects to Agent Engine within your own GCP project. Always review agent code before deploying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Limitations & Known Issues\n",
    "\n",
    "This is a demonstration, not a production system. Here's what can/will break:\n",
    "\n",
    "| What You Try | What Happens | Why |\n",
    "|--------------|--------------|-----|\n",
    "| **Ask for study materials across multiple topics at once** | Retrieval returns wrong content | The agent is designed to match to a single OpenStax chapter; multi-topic queries need more sophisticated retrieval. (There are many good ways to do this.) |\n",
    "| **\"Play podcast about X\"** | Nothing plays (or wrong content) | Audio is pre-generated via NotebookLM, not dynamically created |\n",
    "| **Sidebar navigation, settings, etc.** | Nothing happens | The UI is styled to resemble a Google product, but only the chat functionality is implemented |\n",
    "\n",
    "### What This Demo Is (and Isn't)\n",
    "\n",
    "**Is:** A working example of A2UI's architecture—remote agent deployment, A2A protocol, custom components, and dynamic content generation.\n",
    "\n",
    "**Isn't:** A complete learning platform. The personalization pipeline, multi-topic retrieval, and non-chat UI elements are placeholders demonstrating where real implementations would go."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
