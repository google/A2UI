{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Learning Demo - Quickstart\n",
    "\n",
    "A full-stack A2UI sample demonstrating personalized educational content generation.\n",
    "\n",
    "**Contributed by Google Public Sector's Rapid Innovation Team.**\n",
    "\n",
    "![Personalized Learning Demo](assets/hero.png)\n",
    "\n",
    "---\n",
    "\n",
    "## The Scenario\n",
    "\n",
    "**Maria Thompson** is a pre-med student at Cymbal University preparing for the MCAT. She excels in biology (92%) but struggles with chemistry concepts—particularly the common misconception that \"energy is stored in ATP bonds.\"\n",
    "\n",
    "How we find that information about a student's misconceptions across multiple courses is actually part of a broader project at Google Public Sector. But for now, we're just running with information we have related to one of those misconceptions, represented by the text files in the `learner_context/` directory.\n",
    "\n",
    "This demo includes a [learner profile visualization](http://localhost:5174/maria-context.html) showing Maria's:\n",
    "- Academic background and current proficiency levels\n",
    "- Identified misconceptions to address\n",
    "- Learning preferences (visual-kinesthetic, sports/gym analogies)\n",
    "\n",
    "This profile represents the kind of data a real personalization pipeline would generate from learning management systems, assessment results, and curriculum graphs. Once we have that data, how do we best use it to impact a student's learning trajectory?\n",
    "\n",
    "We think the A2UI framework enables an excellent learning experience, and this demo intends to show how.\n",
    "\n",
    "---\n",
    "\n",
    "## How Content Is Generated\n",
    "\n",
    "**Content Source:** [OpenStax](https://openstax.org/) — free, peer-reviewed textbooks covering 167 chapters across biology, chemistry, physics, and more.\n",
    "\n",
    "**Generation Pipeline:**\n",
    "- User requests a topic (e.g., \"Help me understand ATP\")\n",
    "- The agent uses an LLM to match the topic to the most relevant OpenStax chapter\n",
    "- Content is fetched and transformed into A2UI components (flashcards, quizzes)\n",
    "- The frontend renders whatever A2UI JSON the agent returns\n",
    "\n",
    "**Learn More:**\n",
    "- [How A2UI Works](http://localhost:5174/a2ui-primer.html) — interactive explanation in the demo\n",
    "- [A2UI Specification](../../docs/) — canonical documentation in this repo\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "| Concept | What This Demo Shows |\n",
    "|---------|---------------------|\n",
    "| **Remote Agent Deployment** | Deploy an AI agent to Vertex AI Agent Engine that runs independently from your UI |\n",
    "| **A2A Protocol** | Use the Agent-to-Agent protocol to communicate between your frontend and the remote agent |\n",
    "| **Custom UI Components** | Extend A2UI with custom components (Flashcard, QuizCard) beyond the standard library |\n",
    "| **Dynamic Content Generation** | Generate personalized A2UI JSON on-the-fly based on user requests |\n",
    "| **Dynamic Context from GCS** | Load learner profiles from Cloud Storage — swap context without redeploying |\n",
    "| **Intelligent Content Matching** | Use LLMs to match user topics to relevant textbook content (167 OpenStax chapters) |\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture\n",
    "\n",
    "![Architecture Diagram](assets/architecture.jpg)\n",
    "\n",
    "In production agentic systems:\n",
    "- **Agents run remotely** — they scale independently, can be updated without redeploying the UI, and may be operated by third parties\n",
    "- **UI is decoupled** — the frontend renders whatever A2UI JSON the agent sends, without knowing the agent's implementation\n",
    "- **A2A enables interoperability** — any A2A-compatible agent can power your UI, regardless of how it's built\n",
    "- **Context is dynamic** — learner profiles are loaded from GCS at runtime, enabling personalization without redeployment\n",
    "\n",
    "---\n",
    "\n",
    "## How This Notebook Is Organized\n",
    "\n",
    "| Section | What It Does |\n",
    "|---------|--------------|\n",
    "| **Step 1: Environment Setup** | Creates Python virtual environment and installs all dependencies |\n",
    "| **Step 2: Configuration** | Sets your GCP project ID |\n",
    "| **Step 3: GCP Authentication** | Authenticates with Google Cloud, enables APIs, and uploads learner context to GCS |\n",
    "| **Step 4: Deploy Agent** | Deploys the AI agent to Vertex AI Agent Engine |\n",
    "| **Step 5: Configure & Run** | Creates config files and launches the demo |\n",
    "| **Step 6 (Optional)** | Generate audio/video content with NotebookLM |\n",
    "| **Appendix: Local Development** | Run entirely locally without cloud deployment |\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Node.js 18+** — [Download](https://nodejs.org/)\n",
    "- **Python 3.11+** — [Download](https://www.python.org/downloads/)\n",
    "- **Google Cloud project with billing enabled** — [Console](https://console.cloud.google.com/)\n",
    "- **gcloud CLI installed** — [Install Guide](https://cloud.google.com/sdk/docs/install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Run this cell first to load all Python modules used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "First, we'll create an isolated Python environment and install all dependencies. This ensures the demo doesn't conflict with other Python projects on your system.\n",
    "\n",
    "### 1a. Create Python Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create virtual environment if it doesn't exist\n",
    "venv_path = os.path.join(os.getcwd(), \".venv\")\n",
    "if not os.path.exists(venv_path):\n",
    "    print(\"Creating Python virtual environment...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"venv\", \".venv\"], check=True)\n",
    "    print(f\"✅ Created virtual environment at {venv_path}\")\n",
    "else:\n",
    "    print(f\"✅ Virtual environment already exists at {venv_path}\")\n",
    "\n",
    "print(\"\\n⚠️  IMPORTANT: Restart your Jupyter kernel to use the new environment!\")\n",
    "print(\"   In VS Code: Click the kernel selector (top right) → Select '.venv'\")\n",
    "print(\"   In JupyterLab: Kernel → Change Kernel → Python (.venv)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Install Python Dependencies\n",
    "\n",
    "After selecting the `.venv` kernel, run this cell to install all required Python packages.\n",
    "\n",
    "**Note:** We explicitly use `https://pypi.org/simple/` to ensure packages come from the official Python Package Index, avoiding issues with corporate proxies or custom registries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python dependencies using the canonical PyPI index\n",
    "print(\"Installing Python dependencies from PyPI...\")\n",
    "packages = [\n",
    "    \"google-adk>=0.3.0\",\n",
    "    \"google-genai>=1.0.0\",\n",
    "    \"google-cloud-storage>=2.10.0\",\n",
    "    \"python-dotenv>=1.0.0\",\n",
    "    \"litellm>=1.0.0\",\n",
    "    \"vertexai\",\n",
    "]\n",
    "\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "    \"--index-url\", \"https://pypi.org/simple/\",\n",
    "    \"--trusted-host\", \"pypi.org\",\n",
    "    \"--trusted-host\", \"files.pythonhosted.org\",\n",
    "    *packages\n",
    "], check=True)\n",
    "\n",
    "print(\"✅ Python dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Install Node.js Dependencies\n",
    "\n",
    "Now we'll install the frontend dependencies. This includes the A2UI renderer library and the demo's own packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the A2UI Lit renderer (using public npm registry)\n",
    "print(\"Building A2UI Lit renderer...\")\n",
    "subprocess.run(\n",
    "    \"npm install --registry https://registry.npmjs.org/ && npm run build\",\n",
    "    shell=True,\n",
    "    cwd=\"../../renderers/lit\",\n",
    "    check=True\n",
    ")\n",
    "print(\"✅ A2UI renderer built\")\n",
    "\n",
    "# Install demo dependencies\n",
    "print(\"\\nInstalling demo dependencies...\")\n",
    "subprocess.run(\n",
    "    \"npm install --registry https://registry.npmjs.org/\",\n",
    "    shell=True,\n",
    "    check=True\n",
    ")\n",
    "print(\"✅ Demo dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configuration\n",
    "\n",
    "Set your Google Cloud project ID below. This is the project where the agent will be deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"a2ui-test\"  # <-- CHANGE THIS to your GCP project ID\n",
    "LOCATION = \"us-central1\"  # Agent Engine requires us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: GCP Authentication & API Setup\n",
    "\n",
    "Authenticate with Google Cloud and enable the required APIs. This will open browser windows for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Google Cloud\n",
    "!gcloud auth login\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable required APIs\n",
    "!gcloud services enable aiplatform.googleapis.com\n",
    "!gcloud services enable cloudbuild.googleapis.com\n",
    "!gcloud services enable storage.googleapis.com\n",
    "!gcloud services enable cloudresourcemanager.googleapis.com\n",
    "\n",
    "# Create staging bucket for Agent Engine (if it doesn't exist)\n",
    "!gsutil mb -l us-central1 gs://{PROJECT_ID}_cloudbuild 2>/dev/null || echo \"Staging bucket already exists\"\n",
    "\n",
    "# Create learner context bucket (for dynamic context loading)\n",
    "CONTEXT_BUCKET = f\"{PROJECT_ID}-learner-context\"\n",
    "!gsutil mb -l us-central1 gs://{CONTEXT_BUCKET} 2>/dev/null || echo \"Context bucket already exists\"\n",
    "\n",
    "# Create OpenStax content bucket\n",
    "OPENSTAX_BUCKET = f\"{PROJECT_ID}-openstax\"\n",
    "!gsutil mb -l us-central1 gs://{OPENSTAX_BUCKET} 2>/dev/null || echo \"OpenStax bucket already exists\"\n",
    "\n",
    "# Upload learner context files to GCS\n",
    "print(f\"\\nUploading learner context files to gs://{CONTEXT_BUCKET}/learner_context/...\")\n",
    "!gsutil -m cp learner_context/*.txt gs://{CONTEXT_BUCKET}/learner_context/\n",
    "\n",
    "print(f\"\\n✅ GCP APIs enabled and buckets ready\")\n",
    "print(f\"   Staging bucket: gs://{PROJECT_ID}_cloudbuild\")\n",
    "print(f\"   Context bucket: gs://{CONTEXT_BUCKET}/learner_context/\")\n",
    "print(f\"   OpenStax bucket: gs://{OPENSTAX_BUCKET}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Download OpenStax Textbook Content (Optional but Recommended)\n",
    "\n",
    "The agent fetches **actual OpenStax textbook content** to generate accurate flashcards and quizzes. Content can be fetched:\n",
    "\n",
    "1. **From GitHub (default)** — Works out of the box, but adds latency per request\n",
    "2. **From GCS (recommended)** — Pre-download all modules for faster responses\n",
    "\n",
    "Run the cell below to download all 200+ OpenStax Biology modules to your GCS bucket. This takes ~2 minutes but makes the demo much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download OpenStax Biology modules to GCS (takes ~2 minutes)\n",
    "# This is optional - the agent will fall back to fetching from GitHub if GCS is empty\n",
    "\n",
    "OPENSTAX_BUCKET = f\"{PROJECT_ID}-openstax\"\n",
    "\n",
    "print(f\"Downloading OpenStax Biology modules to gs://{OPENSTAX_BUCKET}/openstax_modules/...\")\n",
    "print(\"This fetches ~200 textbook modules from GitHub and uploads to GCS.\\n\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"download_openstax.py\", \n",
    "     \"--bucket\", OPENSTAX_BUCKET,\n",
    "     \"--prefix\", \"openstax_modules/\",\n",
    "     \"--workers\", \"5\"],\n",
    "    cwd=\"agent\"\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"\\n✅ OpenStax content ready at gs://{OPENSTAX_BUCKET}/openstax_modules/\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Download had issues, but the agent will fall back to GitHub fetching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 4: Deploy the A2UI Agent\n\nThe agent generates personalized learning content and runs on Vertex AI Agent Engine. Deployment takes 2-5 minutes.\n\n**Why deploy remotely?** A2UI is designed for remote agents - your UI runs in the browser while the agent runs on a server. This mirrors real-world architectures where agents scale independently and may even be operated by third parties.\n\n### Dynamic Learner Context\n\nThe agent loads learner profile data from **Cloud Storage at runtime**. This means you can:\n\n1. **Switch students instantly** — Replace the files in `gs://{PROJECT_ID}-learner-context/learner_context/` with a different student's profile\n2. **Update without redeploying** — Change misconceptions, learning preferences, or curriculum focus without touching the agent\n3. **A/B test personalization** — Point different users to different context buckets\n\n**To personalize for a different student:**\n```bash\n# Edit the learner profile locally\nnano learner_context/01_maria_learner_profile.txt\n\n# Upload to GCS (agent picks up changes on next request)\ngsutil cp learner_context/*.txt gs://{PROJECT_ID}-learner-context/learner_context/\n```\n\nThe agent will automatically use the new context for all subsequent requests.\n\n### Performance Note\n\nThe agent uses ADK's context caching for conversation history. For production systems with large textbook corpora, consider Gemini's explicit context cache (requires 32k+ tokens) to cache the full OpenStax content across requests."
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying agent to Vertex AI Agent Engine...\n",
      "This takes 2-5 minutes. Watch for the Resource ID at the end.\n",
      "\n",
      "Deploying Personalized Learning Agent...\n",
      "  Project: a2ui-test\n",
      "  Location: us-central1\n",
      "  Context bucket: gs://a2ui-test-learner-context/learner_context/\n",
      "  OpenStax bucket: gs://a2ui-test-openstax/openstax_modules/\n",
      "\n",
      "Starting deployment (this takes 2-5 minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.reasoning_engines._reasoning_engines:Using bucket a2ui-test_cloudbuild\n",
      "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://a2ui-test_cloudbuild/reasoning_engine/reasoning_engine.pkl\n",
      "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://a2ui-test_cloudbuild/reasoning_engine/requirements.txt\n",
      "INFO:vertexai.reasoning_engines._reasoning_engines:Creating in-memory tarfile of extra_packages\n",
      "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://a2ui-test_cloudbuild/reasoning_engine/dependencies.tar.gz\n",
      "INFO:vertexai.reasoning_engines._reasoning_engines:Creating ReasoningEngine\n",
      "INFO:vertexai.reasoning_engines._reasoning_engines:Create ReasoningEngine backing LRO: projects/854605452886/locations/us-central1/reasoningEngines/1262567003151925248/operations/1228415536338042880\n",
      "INFO:vertexai.reasoning_engines._reasoning_engines:ReasoningEngine created. Resource name: projects/854605452886/locations/us-central1/reasoningEngines/1262567003151925248\n",
      "INFO:vertexai.reasoning_engines._reasoning_engines:To use this ReasoningEngine in another session:\n",
      "INFO:vertexai.reasoning_engines._reasoning_engines:reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/854605452886/locations/us-central1/reasoningEngines/1262567003151925248')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEPLOYMENT SUCCESSFUL!\n",
      "============================================================\n",
      "Resource Name: projects/854605452886/locations/us-central1/reasoningEngines/1262567003151925248\n",
      "Resource ID: 1262567003151925248\n",
      "Context Bucket: gs://a2ui-test-learner-context/learner_context/\n",
      "OpenStax Bucket: gs://a2ui-test-openstax/openstax_modules/\n",
      "\n",
      "Next steps:\n",
      "  1. Copy the Resource ID above\n",
      "  2. Paste it into the notebook's AGENT_RESOURCE_ID variable\n",
      "  3. Upload learner context files to gs://a2ui-test-learner-context/learner_context/\n",
      "  4. Run the remaining notebook cells to configure and start the demo\n",
      "\n",
      "✅ Deployment complete! Copy the Resource ID from the output above.\n"
     ]
    }
   ],
   "source": [
    "# Deploy the agent to Vertex AI Agent Engine (takes 2-5 minutes)\n",
    "# No wheel needed - the ServerSideAgent class is self-contained\n",
    "print(\"Deploying agent to Vertex AI Agent Engine...\")\n",
    "print(\"This takes 2-5 minutes. Watch for the Resource ID at the end.\\n\")\n",
    "\n",
    "# Use the context bucket created in Step 3\n",
    "CONTEXT_BUCKET = f\"{PROJECT_ID}-learner-context\"\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"deploy.py\", \n",
    "     \"--project\", PROJECT_ID, \n",
    "     \"--location\", LOCATION,\n",
    "     \"--context-bucket\", CONTEXT_BUCKET]\n",
    ")\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"\\n❌ Deployment failed. Check the error messages above.\")\n",
    "else:\n",
    "    print(\"\\n✅ Deployment complete! Copy the Resource ID from the output above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Configure & Run\n",
    "\n",
    "Fill in the Resource ID from the deployment output above, then create the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Number: 854605452886\n"
     ]
    }
   ],
   "source": [
    "# Get your project NUMBER (different from project ID)\n",
    "result = subprocess.run(\n",
    "    [\"gcloud\", \"projects\", \"describe\", PROJECT_ID, \"--format=value(projectNumber)\"], \n",
    "    capture_output=True, text=True\n",
    ")\n",
    "PROJECT_NUMBER = result.stdout.strip()\n",
    "print(f\"Project Number: {PROJECT_NUMBER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the Resource ID from the deployment output in Step 4\n",
    "AGENT_RESOURCE_ID = \"1262567003151925248\"  # <-- PASTE YOUR RESOURCE ID HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created .env file:\n",
      "# Generated by Quickstart.ipynb\n",
      "GOOGLE_CLOUD_PROJECT=a2ui-test\n",
      "AGENT_ENGINE_PROJECT_NUMBER=854605452886\n",
      "AGENT_ENGINE_RESOURCE_ID=1262567003151925248\n",
      "\n",
      "✅ Configuration complete!\n"
     ]
    }
   ],
   "source": [
    "# Create .env file\n",
    "env_content = f\"\"\"# Generated by Quickstart.ipynb\n",
    "GOOGLE_CLOUD_PROJECT={PROJECT_ID}\n",
    "AGENT_ENGINE_PROJECT_NUMBER={PROJECT_NUMBER}\n",
    "AGENT_ENGINE_RESOURCE_ID={AGENT_RESOURCE_ID}\n",
    "\"\"\"\n",
    "\n",
    "with open(\".env\", \"w\") as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "print(\"Created .env file:\")\n",
    "print(env_content)\n",
    "print(\"✅ Configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Demo\n",
    "\n",
    "Everything is set up! Run these commands in your terminal (not in the notebook):\n",
    "\n",
    "```bash\n",
    "cd samples/personalized_learning\n",
    "npm run dev\n",
    "```\n",
    "\n",
    "Then open **http://localhost:5174**\n",
    "\n",
    "### Try These Prompts\n",
    "\n",
    "| Prompt | What Happens |\n",
    "|--------|-------------|\n",
    "| \"Help me understand ATP\" | Generates flashcards from OpenStax |\n",
    "| \"Quiz me on bond energy\" | Interactive quiz cards |\n",
    "| \"Play the podcast\" | Audio player (requires Step 6) |\n",
    "| \"Show me a video\" | Video player (requires Step 6) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6 (Optional): Generate Audio & Video with NotebookLM\n",
    "\n",
    "The demo includes audio and video players, but you need to generate the media files. NotebookLM can create personalized podcasts based on the learner context.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- A Google account with access to [NotebookLM](https://notebooklm.google.com/)\n",
    "- The `learner_context/` files from this demo\n",
    "\n",
    "---\n",
    "\n",
    "### Part A: Generate a Personalized Podcast\n",
    "\n",
    "**1. Create a NotebookLM Notebook**\n",
    "\n",
    "Go to [notebooklm.google.com](https://notebooklm.google.com/) and create a new notebook.\n",
    "\n",
    "**2. Upload Learner Context Files**\n",
    "\n",
    "Upload all files from the `learner_context/` directory:\n",
    "- `01_maria_learner_profile.txt` - Maria's background and learning preferences  \n",
    "- `02_chemistry_bond_energy.txt` - Bond energy concepts\n",
    "- `03_chemistry_thermodynamics.txt` - Thermodynamics content\n",
    "- `04_biology_atp_cellular_respiration.txt` - ATP and cellular respiration\n",
    "- `05_misconception_resolution.txt` - Common misconceptions to address\n",
    "- `06_mcat_practice_concepts.txt` - MCAT-focused content\n",
    "\n",
    "These files give NotebookLM the context to generate personalized content.\n",
    "\n",
    "**3. Generate the Audio Overview**\n",
    "\n",
    "- Click **Notebook guide** in the right sidebar\n",
    "- Click **Audio Overview** → **Generate**\n",
    "- Wait for generation to complete (typically 2-5 minutes)\n",
    "- NotebookLM will create a podcast-style discussion about the uploaded content\n",
    "\n",
    "**4. Customize the Audio (Optional)**\n",
    "\n",
    "Before generating, you can click **Customize** to provide specific instructions:\n",
    "\n",
    "```\n",
    "Create a podcast for Maria, a pre-med student preparing for the MCAT. \n",
    "Use gym and fitness analogies since she loves working out.\n",
    "Focus on explaining why \"energy stored in bonds\" is a misconception.\n",
    "Make it conversational and engaging, about 5-7 minutes long.\n",
    "```\n",
    "\n",
    "**5. Download and Install the Podcast**\n",
    "\n",
    "- Once generated, click the **⋮** menu on the audio player\n",
    "- Select **Download**\n",
    "- Save the file as `podcast.m4a`\n",
    "- Copy to the demo's assets directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your downloaded podcast to the assets directory\n",
    "# Replace ~/Downloads/podcast.m4a with your actual download path\n",
    "!cp ~/Downloads/podcast.m4a public/assets/podcast.m4a\n",
    "\n",
    "# Verify the file was copied\n",
    "!ls -la public/assets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Part B: Create a Video\n",
    "\n",
    "In NotebookLM with your learner context loaded:\n",
    "- In the **studio** tab, click \"Video Overview\"\n",
    "- This creates a video file you can view and export\n",
    "\n",
    "Export your video as MP4 and copy to the assets directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your video to the assets directory\n",
    "# Replace ~/Downloads/demo.mp4 with your actual file path\n",
    "!cp ~/Downloads/demo.mp4 public/assets/demo.mp4\n",
    "\n",
    "# Verify both media files are in place\n",
    "!ls -la public/assets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Use Placeholder/Stock Content\n",
    "\n",
    "For demo purposes, you can use any MP4 video file. Rename it to `demo.mp4` and place it in `public/assets/`.\n",
    "\n",
    "---\n",
    "\n",
    "### Verify Media Files\n",
    "\n",
    "After copying your files, verify they're accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Media files status:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "podcast_path = \"public/assets/podcast.m4a\"\n",
    "video_path = \"public/assets/demo.mp4\"\n",
    "\n",
    "if os.path.exists(podcast_path):\n",
    "    size_mb = os.path.getsize(podcast_path) / (1024 * 1024)\n",
    "    print(f\"✅ Podcast: {podcast_path} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"❌ Podcast: {podcast_path} NOT FOUND\")\n",
    "    \n",
    "if os.path.exists(video_path):\n",
    "    size_mb = os.path.getsize(video_path) / (1024 * 1024)\n",
    "    print(f\"✅ Video: {video_path} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"❌ Video: {video_path} NOT FOUND\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"\\nRun 'npm run dev' and try:\")\n",
    "print('  • \"Play the podcast\" - to hear the audio')\n",
    "print('  • \"Show me a video\" - to watch the video')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Content Attribution\n",
    "\n",
    "### OpenStax\n",
    "\n",
    "Educational content is sourced from [OpenStax](https://openstax.org/), licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Specifically: [Biology for AP® Courses](https://openstax.org/details/books/biology-ap-courses) - OpenStax, Rice University\n",
    "\n",
    "---\n",
    "\n",
    "## Security Notice\n",
    "\n",
    "> **Warning:** When building production applications, treat any agent outside your control as potentially untrusted. This demo connects to Agent Engine within your own GCP project. Always review agent code before deploying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Limitations & Known Issues\n",
    "\n",
    "This is a demonstration, not a production system. Here's what can/will break:\n",
    "\n",
    "| What You Try | What Happens | Why |\n",
    "|--------------|--------------|-----|\n",
    "| **Ask for study materials across multiple topics at once** | Retrieval returns wrong content | The agent is designed to match to a single OpenStax chapter; multi-topic queries need more sophisticated retrieval. (There are many good ways to do this.) |\n",
    "| **\"Play podcast about X\"** | Nothing plays (or wrong content) | Audio is pre-generated via NotebookLM, not dynamically created |\n",
    "| **Sidebar navigation, settings, etc.** | Nothing happens | The UI is styled to resemble a Google product, but only the chat functionality is implemented |\n",
    "\n",
    "### What This Demo Is (and Isn't)\n",
    "\n",
    "**Is:** A working example of A2UI's architecture—remote agent deployment, A2A protocol, custom components, and dynamic content generation.\n",
    "\n",
    "**Isn't:** A complete learning platform. The personalization pipeline, multi-topic retrieval, and non-chat UI elements are placeholders demonstrating where real implementations would go."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}